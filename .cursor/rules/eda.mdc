---
description: 
globs: 
alwaysApply: true
---
# 데이터 분석 프로젝트 규칙

## 1. 기본 코딩 규칙
- 없는 함수나 변수 클래스를 선언하지 않고 사용하지 않는다. 어떤 변수나 함수나 클래스 등을 호출해서 쓸 때에는 먼저, 정의되어있는 것인지 반드시 확인한다.(코드단에서 확인하는 것이 아닌, 코드로 만들기 전에 미리 확인한다. )
- 이모지를 사용하지 않는다.
- 과도한 try-except 문을 사용하지 않는다.
- 수정 시 함수명, 변수명, 클래스명 등을 임의로 변경하지 않는다.
- 일관성 있게 코드를 설계한다.

## 2. 데이터 분석 방법론
- 데이터 분석 작업 시 최대한 다양한 접근을 시도한다.
- 다양하고 전문적인 통계적 기법을 적극 활용하여 최대한 많은 인사이트를 도출한다.
- 통계적 오류가 없도록 하며, 특정한 방법을 선택한 구체적인 근거를 남긴다.
- 가설 설정과 검증 과정을 명확히 한다.
- 다층적 분석을 통해 표면적 패턴뿐만 아니라 숨겨진 구조와 관계를 탐색한다.
- 도메인 특화 분석 기법을 적극 도입하여 전문성을 높인다.

## 3. 최신 연구 및 근거 활용
- 분석 방법론 선택 시 최신 학술 논문과 연구 결과를 적극적으로 참조한다.
- 사용한 통계 기법이나 모델에 대한 이론적 배경과 최신 연구 동향을 제시한다.
- 분석 결과 해석 시 관련 분야의 최신 연구 성과와 비교 검토한다.
- 참고한 연구나 논문의 출처를 명확히 기록하고 인용한다.
- 해당 분야의 베스트 프랙티스와 최신 트렌드를 반영한 분석을 수행한다.
- 새로운 방법론이나 기법 적용 시 그 효과와 한계를 최신 연구 기반으로 설명한다.

## 4. 깊이 있는 인사이트 도출
- 단순한 기술 통계를 넘어서 인과관계, 상호작용, 비선형 관계를 탐색한다.
- 다차원적 관점에서 데이터를 해석하고 복합적 요인들의 영향을 분석한다.
- 시간적, 공간적, 맥락적 요소를 고려한 심층 분석을 수행한다.
- 예외적 사례나 특이점에 대한 심도 있는 분석을 통해 새로운 통찰을 도출한다.
- 다양한 관점과 가설을 검증하여 편향되지 않은 결론을 도출한다.
- 분석 결과의 실무적 함의와 전략적 시사점을 구체적으로 제시한다.

## 5. 고급 분석 기법 활용
- 머신러닝, 딥러닝 등 고급 분석 기법을 적절히 활용한다.
- 베이지안 추론, 시뮬레이션, 부트스트래핑 등 현대적 통계 기법을 도입한다.
- 앙상블 방법, 교차 검증 등을 통해 분석 결과의 견고성을 확보한다.
- 차원 축소, 클러스터링, 네트워크 분석 등을 통해 데이터의 숨겨진 구조를 발견한다.
- 텍스트 마이닝, 자연어 처리 등을 활용한 비정형 데이터 분석을 수행한다.

## 6. 코드 품질 관리
- 변수명은 명확하고 의미있게 생성한다.
- 에러가 발생할 수 있는 부분은 미리 예외 처리 및 로그를 통해 디버깅에 용이하게 한다.
- 전문가 수준의 코드를 작성하되 불필요하게 복잡하지 않게 작성한다.
- 명확하고 읽기 쉬운 코드를 작성한다.
- 명확하고 간결하며 전문성 있는 주석을 처리한다.
- 코드의 모듈화와 재사용성을 고려한다.

## 7. 데이터 시각화
- 파이썬 시각화 관련 코드 작성 시 한국어 설정 및 기본 설정을 유념한다.
- 전문성 있고 심미적 기능이 뛰어난 시각화 코드를 작성한다.
- 색상, 폰트, 레이아웃 등을 고려하여 직관적인 시각화를 생성한다.
- 범례, 축 라벨, 제목 등을 명확히 표기한다.
- 인터랙티브 시각화를 통해 다차원적 탐색이 가능하도록 한다.
- 스토리텔링 관점에서 시각화를 구성하여 인사이트 전달력을 높인다.

## 8. 문서화 규칙
- 가독성을 높인다.
- 구체적인 설명을 포함한다.
- 문서가 길어지면 링크 목차 개요를 통해 쉽게 볼 수 있게 설정한다.
- 분석 결과에 대한 해석과 비즈니스 인사이트를 포함한다.
- 사용된 방법론의 이론적 배경과 선택 근거를 상세히 기록한다.
- 제한사항과 추후 개선 방향을 명시한다.
- 참고 문헌과 데이터 출처를 체계적으로 정리한다.

## 9. 데이터 처리 원칙
- 데이터 무결성을 보장한다.
- 결측치, 이상치 처리 방법을 명확히 기록한다.
- 데이터 전처리 과정을 단계별로 문서화한다.
- 원본 데이터의 백업과 버전 관리를 수행한다.
- 데이터 품질 평가와 검증 과정을 체계화한다.
- 민감 정보 보호와 개인정보 처리 원칙을 준수한다.

## 10. 성능 최적화
- 대용량 데이터 처리 시 메모리 효율성을 고려한다.
- 반복적인 연산은 벡터화를 활용한다.
- 필요시 병렬 처리를 고려한다.
- 연산 복잡도를 고려한 알고리즘 선택을 한다.

## 11. 재현성 보장
- 랜덤 시드를 고정하여 결과의 재현성을 보장한다.
- 환경 설정 및 라이브러리 버전을 명시한다.
- 분석 과정을 단계별로 명확히 기록한다.
- 코드와 데이터의 버전 관리를 체계적으로 수행한다.

## 12. 검증 및 평가
- 분석 결과의 통계적 유의성과 실무적 유의성을 구분하여 평가한다.
- 교차 검증, 홀드아웃 검증 등을 통해 모델의 일반화 성능을 확인한다.
- 민감도 분석을 통해 결과의 안정성을 검증한다.
- 외부 데이터나 도메인 전문가의 의견을 통해 결과를 검증한다.

## 13. 응답 방식
- 항상 한국어로 응답한다.
- ~한다, ~이다와 같이 명확한 문체를 사용한다.
- 지어낸 거짓 정보를 사용하지 않는다.
- 전문 용어 사용 시 필요에 따라 명확한 정의나 설명을 제공한다.

